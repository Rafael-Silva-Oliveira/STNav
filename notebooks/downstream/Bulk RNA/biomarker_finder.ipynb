{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sksurv.metrics import (concordance_index_censored, \n",
    "                            cumulative_dynamic_auc)\n",
    "from sksurv.metrics import integrated_brier_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sksurv.datasets import load_breast_cancer\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis, CoxPHSurvivalAnalysis\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "# Initialize and run the analysis\n",
    "from matplotlib.colors import rgb2hex\n",
    "from pydeseq2 import preprocessing, dds, ds\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "import seaborn as sns\n",
    "# Standard library imports\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from itertools import combinations, cycle\n",
    "\n",
    "# Third-party library imports\n",
    "import anndata\n",
    "import decoupler as dc\n",
    "import gseapy as gp\n",
    "from gseapy import prerank\n",
    "from gseapy.plot import dotplot, gseaplot\n",
    "import liana as ln\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, LogNorm, rgb2hex, to_rgba\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import Ellipse, Polygon\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import pandas as pd\n",
    "import PyComplexHeatmap as pch\n",
    "from pydeseq2 import preprocessing, dds, ds\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "import scanpy as sc\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.cluster import hierarchy\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import linregress, median_abs_deviation\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    calinski_harabasz_score,\n",
    "    confusion_matrix,\n",
    "    davies_bouldin_score,\n",
    "    make_scorer,\n",
    "    roc_auc_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "from sklearn.mixture import BayesianGaussianMixture, GaussianMixture\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import plot_tree\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from tqdm import tqdm\n",
    "import umap\n",
    "\n",
    "# Local imports\n",
    "from cnmf import cNMF\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Set global rcParams for consistent formatting\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white',\n",
    "    'savefig.facecolor': 'white',\n",
    "    'legend.frameon': True,\n",
    "    'legend.edgecolor': 'black',\n",
    "    'legend.labelcolor': 'black',\n",
    "    'legend.fontsize': 12,\n",
    "    'axes.labelcolor': 'black',\n",
    "    'xtick.color': 'black',\n",
    "    'ytick.color': 'black',\n",
    "    'text.color': 'black',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_from_conversion(adata):\n",
    "    conversion_info = adata.uns.get('conversion_info', {})\n",
    "\n",
    "    for key, original_type in conversion_info.items():\n",
    "        df_name, col = key.split(':')\n",
    "        df = getattr(adata, df_name)\n",
    "\n",
    "        if 'datetime' in original_type.lower():\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "        elif 'timedelta' in original_type.lower():\n",
    "            df[col] = pd.to_timedelta(df[col])\n",
    "        elif original_type == 'category':\n",
    "            df[col] = df[col].astype('category')\n",
    "        elif 'int' in original_type.lower():\n",
    "            df[col] = df[col].astype('Int64')  # Use nullable integer type\n",
    "        elif 'float' in original_type.lower():\n",
    "            df[col] = df[col].astype('float64')\n",
    "        elif 'bool' in original_type.lower():\n",
    "            df[col] = df[col].astype('boolean')\n",
    "        # Other types will remain as they are\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DEGAnalysis:\n",
    "    def __init__(self, adata, design_factor, layer='raw_counts', output_dir='deg_analysis_results'):\n",
    "        self.original_adata = adata\n",
    "        self.design_factor = design_factor\n",
    "        self.layer = layer\n",
    "        self.adata = None\n",
    "        self.dds = None\n",
    "        self.results = {}\n",
    "        self.colors = self._generate_colors()\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def _generate_colors(self):\n",
    "        unique_groups = self.original_adata.obs[self.design_factor].unique()\n",
    "        n_colors = len(unique_groups)\n",
    "        color_map = plt.cm.get_cmap('tab20')\n",
    "        colors = {group: rgb2hex(color_map(i/n_colors)) for i, group in enumerate(unique_groups)}\n",
    "        return colors\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.adata = self.original_adata.copy()\n",
    "        if self.layer in self.adata.layers:\n",
    "            self.adata.X = self.adata.layers[self.layer].copy()\n",
    "        elif self.layer != 'X':\n",
    "            raise ValueError(f\"Layer '{self.layer}' not found in the AnnData object.\")\n",
    "        min_val = self.adata.X.min()\n",
    "        if min_val < 0:\n",
    "            self.adata.X -= min_val\n",
    "\n",
    "    def create_dds(self):\n",
    "        if self.adata is None:\n",
    "            self.prepare_data()\n",
    "        self.dds = DeseqDataSet(\n",
    "            adata=self.adata,\n",
    "            design_factors=self.design_factor,\n",
    "            refit_cooks=True,\n",
    "        )\n",
    "        self.dds.deseq2()\n",
    "\n",
    "    def run_comparisons(self):\n",
    "        subtypes = sorted(self.adata.obs[self.design_factor].unique().tolist())\n",
    "        n_subtypes = len(subtypes)\n",
    "        \n",
    "        # One-vs-One comparisons\n",
    "        for i in range(n_subtypes):\n",
    "            for j in range(i+1, n_subtypes):\n",
    "                self._run_comparison(subtypes[i], subtypes[j])\n",
    "        \n",
    "        # One-vs-Rest comparisons\n",
    "        for subtype in subtypes:\n",
    "            self._run_comparison(subtype, 'rest', one_vs_rest=True)\n",
    "\n",
    "    def _run_comparison(self, group1, group2, one_vs_rest=False):\n",
    "        comparison_name = f\"{group1}_vs_{group2}\"\n",
    "        if one_vs_rest:\n",
    "            temp_counts = pd.DataFrame(self.adata.X, index=self.adata.obs_names, columns=self.adata.var_names)\n",
    "            temp_metadata = pd.DataFrame({self.design_factor: self.adata.obs[self.design_factor]})\n",
    "            temp_metadata[self.design_factor] = np.where(temp_metadata[self.design_factor] == group1, group1, 'rest')\n",
    "            \n",
    "            temp_dds = DeseqDataSet(\n",
    "                counts=temp_counts,\n",
    "                metadata=temp_metadata,\n",
    "                design_factors=self.design_factor,\n",
    "                refit_cooks=True,\n",
    "            )\n",
    "            temp_dds.deseq2()\n",
    "            res = DeseqStats(temp_dds, contrast=[self.design_factor, group1, 'rest'])\n",
    "        else:\n",
    "            res = DeseqStats(self.dds, contrast=[self.design_factor, group1, group2])\n",
    "        \n",
    "        res.summary()\n",
    "        res.results_df[\"Log2FC_pval\"] = res.results_df[\"log2FoldChange\"] * -np.log10(res.results_df[\"pvalue\"])\n",
    "        res.results_df = res.results_df.sort_values(\"Log2FC_pval\", ascending=False)\n",
    "        self.results[comparison_name] = res\n",
    "        \n",
    "    def create_volcano_plots(self, highlight_dict=None):\n",
    "        for comparison_name, res in self.results.items():\n",
    "            self._create_volcano_plot(res.results_df, comparison_name, highlight_dict)\n",
    "\n",
    "    def _create_volcano_plot(self, deg_df, comparison_name, highlight_dict=None):\n",
    "        with plt.rc_context({'figure.figsize': (12, 8)}):\n",
    "            plt.figure()\n",
    "            \n",
    "            # Plot all genes\n",
    "            plt.scatter(deg_df['log2FoldChange'], -np.log10(deg_df['pvalue']), \n",
    "                        alpha=0.6, s=3, color='grey', label='Other')\n",
    "            \n",
    "            # Highlight significant genes\n",
    "            significant = (deg_df['padj'] < 0.05) & (abs(deg_df['log2FoldChange']) > 0.5)\n",
    "            plt.scatter(deg_df.loc[significant, 'log2FoldChange'], \n",
    "                        -np.log10(deg_df.loc[significant, 'pvalue']), \n",
    "                        alpha=0.6, s=3, color='lightgrey', label='Significant')\n",
    "            \n",
    "            # Highlight genes from the dictionary\n",
    "            if highlight_dict:\n",
    "                colors = sns.color_palette(\"husl\", len(highlight_dict))\n",
    "                for (group, genes), color in zip(highlight_dict.items(), colors):\n",
    "                    mask = deg_df.index.isin(genes)\n",
    "                    plt.scatter(deg_df.loc[mask, 'log2FoldChange'], \n",
    "                                -np.log10(deg_df.loc[mask, 'pvalue']),\n",
    "                                alpha=0.8, s=30, color=color, label=group)\n",
    "                    \n",
    "                    # Annotate these genes\n",
    "                    for gene in genes:\n",
    "                        if gene in deg_df.index:\n",
    "                            gene_data = deg_df.loc[gene]\n",
    "                            plt.annotate(gene, \n",
    "                                         (gene_data['log2FoldChange'], -np.log10(gene_data['pvalue'])),\n",
    "                                         xytext=(5, 5), textcoords='offset points', \n",
    "                                         ha='left', va='bottom',\n",
    "                                         fontsize=8,\n",
    "                                         bbox=dict(boxstyle='round,pad=0.1', fc='white', ec='none', alpha=0.7),\n",
    "                                         arrowprops=dict(arrowstyle='->', color='black', lw=0.5))\n",
    "            else:\n",
    "                # If no highlight_dict, annotate top genes as before\n",
    "                top_genes = deg_df.sort_values('pvalue').head(20)\n",
    "                for _, gene in top_genes.iterrows():\n",
    "                    plt.annotate(gene.name, \n",
    "                                 (gene['log2FoldChange'], -np.log10(gene['pvalue'])),\n",
    "                                 xytext=(3, 3), textcoords='offset points', \n",
    "                                 ha='left', va='bottom',\n",
    "                                 fontsize=6,\n",
    "                                 bbox=dict(boxstyle='round,pad=0.1', fc='white', ec='none', alpha=0.7),\n",
    "                                 arrowprops=dict(arrowstyle='->', color='black', lw=0.5))\n",
    "            \n",
    "            plt.axvline(x=0.5, color='gray', linestyle='--', linewidth=1)\n",
    "            plt.axvline(x=-0.5, color='gray', linestyle='--', linewidth=1)\n",
    "            plt.axhline(y=-np.log10(0.05), color='gray', linestyle='--', linewidth=1)\n",
    "            \n",
    "            plt.xlabel('Log2 fold change')\n",
    "            plt.ylabel('-Log10 p-value')\n",
    "            plt.title(f'Volcano Plot: {comparison_name}')\n",
    "            \n",
    "            group1, group2 = comparison_name.split('_vs_')\n",
    "            plt.text(0.02, 0.98, f\"Positive log2FC: Upregulated in {group1}\\nNegative log2FC: Upregulated in {group2}\",\n",
    "                     transform=plt.gca().transAxes, va='top', ha='left', fontsize=8, \n",
    "                     bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "            \n",
    "            if highlight_dict:\n",
    "                plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(self.output_dir, f'volcano_plot_{comparison_name}.png'), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "    def create_clustermaps(self, marker_list=None, padj_threshold=0.05, log2fc_threshold=1):\n",
    "        for comparison_name, res in self.results.items():\n",
    "            self._create_clustermap(res.results_df, comparison_name, marker_list, padj_threshold, log2fc_threshold)\n",
    "            \n",
    "    def _create_clustermap(self, results_df, comparison_name, marker_list=None, padj_threshold=0.05, log2fc_threshold=1):\n",
    "        cluster1, cluster2 = comparison_name.split('_vs_')\n",
    "        significant_genes = results_df[(results_df['padj'] < padj_threshold) & \n",
    "                                    (abs(results_df['log2FoldChange']) > log2fc_threshold)].index\n",
    "\n",
    "        if marker_list is not None:\n",
    "            marker_genes = [gene for gene in marker_list if gene in significant_genes]\n",
    "            if len(marker_genes) < 2:\n",
    "                print(f\"Warning: Less than 2 genes from the marker list are present in the significant genes for {comparison_name}.\")\n",
    "                print(\"Using all significant genes instead.\")\n",
    "                genes_to_plot = significant_genes\n",
    "            else:\n",
    "                genes_to_plot = marker_genes\n",
    "        else:\n",
    "            genes_to_plot = significant_genes\n",
    "\n",
    "        if len(genes_to_plot) < 2:\n",
    "            print(f\"Not enough genes to plot for {comparison_name}. Skipping this comparison.\")\n",
    "            return\n",
    "\n",
    "        if cluster2 == 'rest':\n",
    "            dds_sub = self.dds[:, genes_to_plot]\n",
    "        else:\n",
    "            dds_sub = self.dds[self.dds.obs[self.design_factor].isin([cluster1, cluster2]), genes_to_plot]\n",
    "\n",
    "        if dds_sub.shape[1] < 2 or dds_sub.shape[0] < 2:\n",
    "            print(f\"Not enough data to plot for {comparison_name}. Skipping this comparison.\")\n",
    "            print(f\"Number of genes: {dds_sub.shape[1]}, Number of samples: {dds_sub.shape[0]}\")\n",
    "            return\n",
    "\n",
    "        dds_sub = dds_sub[dds_sub.obs[self.design_factor].argsort()]\n",
    "        grapher = pd.DataFrame(dds_sub.layers[\"lognormalized_counts\"].T, index=dds_sub.var_names, columns=dds_sub.obs_names)\n",
    "        col_colors_leiden = dds_sub.obs[self.design_factor].map(self.colors)\n",
    "        \n",
    "        try:\n",
    "            plt.figure(figsize=(30, 15 + 0.2 * len(genes_to_plot)))\n",
    "            g = sns.clustermap(grapher, \n",
    "                            z_score=0,  \n",
    "                            cmap=\"RdBu_r\",\n",
    "                            col_cluster=False, \n",
    "                            row_cluster=True,\n",
    "                            col_colors=col_colors_leiden,\n",
    "                            dendrogram_ratio=(.1, .3),\n",
    "                            robust=True)  # Add robust to handle outliers better\n",
    "            \n",
    "            # Adjust the colorbar to be symmetric around 0\n",
    "            vmax = max(abs(g.ax_heatmap.collections[0].get_clim()))\n",
    "            g.ax_heatmap.collections[0].set_clim(-vmax, vmax)\n",
    "        \n",
    "            \n",
    "            \n",
    "            plt.setp(g.ax_heatmap.get_xticklabels(), rotation=90, ha='center', va='top')\n",
    "            g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), fontsize=8)\n",
    "            \n",
    "            plt.setp(g.ax_heatmap.get_yticklabels(), rotation=0)\n",
    "            \n",
    "            for label in [cluster1, cluster2]:\n",
    "                g.ax_col_dendrogram.bar(0, 0, color=self.colors[label], label=label, linewidth=0)\n",
    "            g.ax_col_dendrogram.legend(title=self.design_factor, loc=\"center\", ncol=2)\n",
    "            \n",
    "            plt.suptitle(f\"Clustermap for {comparison_name}\", fontsize=16, y=1.02)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(self.output_dir, f\"clustermap_{comparison_name}.png\"), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating clustermap for {comparison_name}: {str(e)}\")\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"Successfully created clustermap for {comparison_name} with {len(genes_to_plot)} genes.\")\n",
    "\n",
    "    def get_results(self):\n",
    "        return self.results\n",
    "\n",
    "    def save_results(self):\n",
    "        for comparison_name, res in self.results.items():\n",
    "            res.results_df.to_csv(os.path.join(self.output_dir, f\"DEG_results_{comparison_name}.csv\"))\n",
    "        print(f\"All DEG results have been saved to CSV files in the {self.output_dir} folder.\")\n",
    "\n",
    "    def create_boxplots(self, genes_to_plot, test='ttest', figsize=(20, 5), save_path=None):\n",
    "        adata_subset, valid_genes = self._prepare_data_for_boxplots(genes_to_plot)\n",
    "        \n",
    "        if not valid_genes:\n",
    "            print(\"No valid genes found in the dataset.\")\n",
    "            return\n",
    "\n",
    "        n_genes = len(valid_genes)\n",
    "        fig, axes = plt.subplots(1, n_genes, figsize=figsize)\n",
    "        if n_genes == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for i, gene in enumerate(valid_genes):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            data = pd.DataFrame({\n",
    "                'expression': adata_subset[:, gene].X.flatten(),\n",
    "                self.design_factor: adata_subset.obs[self.design_factor]\n",
    "            })\n",
    "            \n",
    "            clusters = sorted(data[self.design_factor].unique())\n",
    "            cluster_to_pos = {cluster: idx for idx, cluster in enumerate(clusters)}\n",
    "            \n",
    "            sns.boxplot(data=data, x=self.design_factor, y='expression', ax=ax, order=clusters, palette=self.colors)\n",
    "            sns.stripplot(data=data, x=self.design_factor, y='expression', color='black', size=2, alpha=0.4, ax=ax, order=clusters)\n",
    "            \n",
    "            comparisons = list(itertools.combinations(clusters, 2))\n",
    "            max_bars = len(comparisons)\n",
    "            \n",
    "            plot_top = ax.get_ylim()[1]\n",
    "            bar_height = plot_top * 0.05\n",
    "            spacing = plot_top * 0.1\n",
    "            \n",
    "            for idx, (c1, c2) in enumerate(comparisons):\n",
    "                data1 = data[data[self.design_factor] == c1]['expression']\n",
    "                data2 = data[data[self.design_factor] == c2]['expression']\n",
    "                p_value = self._perform_test(data1, data2, test, gene, f\"{self.design_factor} {c1}\", f\"{self.design_factor} {c2}\")\n",
    "                \n",
    "                y_pos = plot_top + spacing + (bar_height + spacing) * idx\n",
    "                \n",
    "                x1, x2 = cluster_to_pos[c1], cluster_to_pos[c2]\n",
    "                ax.plot([x1, x1, x2, x2], [y_pos, y_pos + bar_height, y_pos + bar_height, y_pos], lw=1.5, c='black')\n",
    "                significance = self._get_stars(p_value)\n",
    "                ax.text((x1 + x2) / 2, y_pos + bar_height, significance, ha='center', va='bottom', fontsize=10)\n",
    "            \n",
    "            ax.set_title(f'{gene}', fontsize=14)\n",
    "            ax.set_xlabel(self.design_factor.capitalize(), fontsize=12)\n",
    "            ax.set_ylabel('log2(CPM+1)' if i == 0 else '', fontsize=12)\n",
    "            ax.set_ylim(0, plot_top + (bar_height + spacing) * (max_bars + 1))\n",
    "            ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "            \n",
    "            ax.set_xticks(range(len(clusters)))\n",
    "            ax.set_xticklabels(clusters)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(os.path.join(self.output_dir, save_path), dpi=300, bbox_inches='tight')\n",
    "            print(f\"Figure saved to {os.path.join(self.output_dir, save_path)}\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        missing_genes = set(genes_to_plot) - set(valid_genes)\n",
    "        if missing_genes:\n",
    "            print(f\"The following genes were not found in the dataset: {', '.join(missing_genes)}\")\n",
    "\n",
    "    def create_volcano_grid(self, highlight_genes=None):\n",
    "        # Get unique group names\n",
    "        group_names = sorted(set([k.split('_vs_')[0] for k in self.results.keys() if '_vs_' in k]))\n",
    "        n_groups = len(group_names)\n",
    "\n",
    "        fig = plt.figure(figsize=(4*n_groups, 4*n_groups))\n",
    "        gs = GridSpec(n_groups, n_groups)\n",
    "\n",
    "        for i, group1 in enumerate(group_names):\n",
    "            for j, group2 in enumerate(group_names):\n",
    "                if i < j:  # Upper triangle\n",
    "                    ax = fig.add_subplot(gs[i, j])\n",
    "                    comparison = f\"{group1}_vs_{group2}\"\n",
    "                    if comparison in self.results:\n",
    "                        self._plot_volcano(ax, self.results[comparison].results_df, f'{group1} vs. {group2}', self.colors[group1], highlight_genes=highlight_genes)\n",
    "                elif i == j:  # Diagonal\n",
    "                    ax = fig.add_subplot(gs[i, i])\n",
    "                    comparison = f\"{group1}_vs_rest\"\n",
    "                    if comparison in self.results:\n",
    "                        self._plot_volcano(ax, self.results[comparison].results_df, f'{group1} vs. Others', self.colors[group1], highlight_genes=highlight_genes)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.output_dir, \"volcano_grid.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    def _prepare_data_for_boxplots(self, genes_to_plot):\n",
    "        valid_genes = [gene for gene in genes_to_plot if gene in self.original_adata.var_names]\n",
    "        \n",
    "        adata_full = self.original_adata.copy()\n",
    "        sc.pp.normalize_total(adata_full, target_sum=1e6)\n",
    "        sc.pp.log1p(adata_full)\n",
    "        \n",
    "        adata_subset = adata_full[:, valid_genes]\n",
    "        \n",
    "        return adata_subset, valid_genes\n",
    "\n",
    "    def _perform_test(self, data1, data2, test_type, gene, group1_name, group2_name):\n",
    "        if test_type == 'mannwhitneyu':\n",
    "            statistic, p_value = stats.mannwhitneyu(data1, data2)\n",
    "        elif test_type == 'ttest':\n",
    "            statistic, p_value = stats.ttest_ind(data1, data2, equal_var=False)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid test type. Choose 'mannwhitneyu' or 'ttest'.\")\n",
    "        \n",
    "        print(f\"\\nGene: {gene}\")\n",
    "        print(f\"Comparison: {group1_name} vs {group2_name}\")\n",
    "        print(f\"{group1_name}: n={len(data1)}, median={np.median(data1):.2f}, mean={np.mean(data1):.2f}\")\n",
    "        print(f\"{group2_name}: n={len(data2)}, median={np.median(data2):.2f}, mean={np.mean(data2):.2f}\")\n",
    "        print(f\"p-value: {p_value:.4f}\")\n",
    "        print(f\"Significance: {self._get_stars(p_value)}\")\n",
    "        return p_value\n",
    "\n",
    "    def _get_stars(self, p_value):\n",
    "        p_value = round(p_value, 4)\n",
    "        if p_value < 0.001:\n",
    "            return '***'\n",
    "        elif p_value < 0.01:\n",
    "            return '**'\n",
    "        elif p_value < 0.05:\n",
    "            return '*'\n",
    "        else:\n",
    "            return 'ns'\n",
    "\n",
    "    def _plot_volcano(self, ax, results, title, color, top_genes=5, highlight_genes=None):\n",
    "        ax.scatter(results['log2FoldChange'], -np.log10(results['pvalue']), \n",
    "                   alpha=0.6, s=3, color=color)\n",
    "        \n",
    "        ax.axhline(-np.log10(0.05), color='red', linestyle='--', linewidth=0.5)\n",
    "        ax.axvline(-1, color='red', linestyle='--', linewidth=0.5)\n",
    "        ax.axvline(1, color='red', linestyle='--', linewidth=0.5)\n",
    "        \n",
    "        top = results.sort_values('pvalue').head(top_genes)\n",
    "        for _, gene in top.iterrows():\n",
    "            ax.text(gene['log2FoldChange'], -np.log10(gene['pvalue']), gene.name, \n",
    "                    fontsize=6, ha='center', va='bottom', color='black')\n",
    "        \n",
    "        if highlight_genes:\n",
    "            for gene in highlight_genes:\n",
    "                if gene in results.index:\n",
    "                    gene_data = results.loc[gene]\n",
    "                    ax.text(gene_data['log2FoldChange'], -np.log10(gene_data['pvalue']), gene, \n",
    "                            fontsize=6, ha='center', va='bottom', color='red', fontweight='bold')\n",
    "                    ax.scatter(gene_data['log2FoldChange'], -np.log10(gene_data['pvalue']), \n",
    "                               color='red', s=20, zorder=5)\n",
    "        \n",
    "        ax.set_title(title, fontsize=10)\n",
    "        ax.set_xlabel('log2(Fold Change)', fontsize=8)\n",
    "        ax.set_ylabel('-log10(p-value)', fontsize=8)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=6)\n",
    "        ax.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "\n",
    "    def infer_tf_activities(self):\n",
    "        # Retrieve CollecTRI gene regulatory network\n",
    "        collectri = dc.get_collectri(organism='human', split_complexes=False)\n",
    "        \n",
    "        # Prepare data for TF activity inference\n",
    "        mat = self.results['treatment.vs.control'].results_df[['stat']].T.rename(index={'stat': 'treatment.vs.control'})\n",
    "        \n",
    "        # Infer TF activities with ulm\n",
    "        self.tf_acts, tf_pvals = dc.run_ulm(mat=mat, net=collectri, verbose=True)\n",
    "\n",
    "    def plot_tf_activities(self, top=25):\n",
    "        dc.plot_barplot(\n",
    "            acts=self.tf_acts,\n",
    "            contrast='treatment.vs.control',\n",
    "            top=top,\n",
    "            vertical=True,\n",
    "            figsize=(3, 6)\n",
    "        )\n",
    "        plt.savefig(os.path.join(self.output_dir, 'tf_activities.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def infer_pathway_activities(self):\n",
    "        # Retrieve PROGENy model weights\n",
    "        progeny = dc.get_progeny(top=500)\n",
    "        \n",
    "        # Prepare data for pathway activity inference\n",
    "        mat = self.results['treatment.vs.control'].results_df[['stat']].T.rename(index={'stat': 'treatment.vs.control'})\n",
    "        \n",
    "        # Infer pathway activities with mlm\n",
    "        self.pathway_acts, pathway_pvals = dc.run_mlm(mat=mat, net=progeny, verbose=True)\n",
    "\n",
    "    def plot_pathway_activities(self):\n",
    "        dc.plot_barplot(\n",
    "            self.pathway_acts,\n",
    "            'treatment.vs.control',\n",
    "            top=25,\n",
    "            vertical=False,\n",
    "            figsize=(6, 3)\n",
    "        )\n",
    "        plt.savefig(os.path.join(self.output_dir, 'pathway_activities.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def run_functional_enrichment(self):\n",
    "        # Retrieve MSigDB gene sets\n",
    "        msigdb = dc.get_resource('MSigDB')\n",
    "        msigdb = msigdb[msigdb['collection']=='hallmark']\n",
    "        msigdb = msigdb[~msigdb.duplicated(['geneset', 'genesymbol'])]\n",
    "        msigdb.loc[:, 'geneset'] = [name.split('HALLMARK_')[1] for name in msigdb['geneset']]\n",
    "\n",
    "        # Prepare data for enrichment analysis\n",
    "        top_genes = self.results['treatment.vs.control'].results_df[self.results['treatment.vs.control'].results_df['padj'] < 0.05]\n",
    "\n",
    "        # Run ora\n",
    "        self.enr_pvals = dc.get_ora_df(\n",
    "            df=top_genes,\n",
    "            net=msigdb,\n",
    "            source='geneset',\n",
    "            target='genesymbol'\n",
    "        )\n",
    "\n",
    "    def plot_functional_enrichment(self, top=15):\n",
    "        dc.plot_dotplot(\n",
    "            self.enr_pvals.sort_values('Combined score', ascending=False).head(top),\n",
    "            x='Combined score',\n",
    "            y='Term',\n",
    "            s='Odds ratio',\n",
    "            c='FDR p-value',\n",
    "            scale=1.5,\n",
    "            figsize=(3, 6)\n",
    "        )\n",
    "        plt.savefig(os.path.join(self.output_dir, 'functional_enrichment.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "import os\n",
    "\n",
    "def get_top_genes(source_paths: Dict[str, str], n_genes: int = 10) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Get top genes from CSV files containing differential expression results.\n",
    "    \n",
    "    Args:\n",
    "        source_paths: Dictionary where keys are comparison names and values are paths to CSV files\n",
    "        n_genes: Number of top genes to return\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing top genes for each comparison\n",
    "    \"\"\"\n",
    "    deg_results = {}\n",
    "    \n",
    "    for comparison, file_path in source_paths.items():\n",
    "        # Read CSV file\n",
    "        results = pd.read_csv(file_path)\n",
    "        \n",
    "        # Sort by stat column in descending order\n",
    "        results = results.sort_values('stat', ascending=False)\n",
    "        \n",
    "        # Print top genes info\n",
    "        print(f\"\\n{comparison} Top Genes:\")\n",
    "        print(results[['gene_identifier', 'stat', 'log2FoldChange', 'padj']].head(n_genes))\n",
    "        \n",
    "        # Store top gene identifiers\n",
    "        deg_results[comparison] = results['gene_identifier'].head(n_genes).tolist()\n",
    "\n",
    "    return deg_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "km_data_ttp = pd.read_csv(r\"/home/rafaed/work/RO_src/Projects/THORA/StatisticalAnalysis/scripts/data_ttp.csv\")\n",
    "km_data_os = pd.read_csv(r\"/home/rafaed/work/RO_src/Projects/THORA/StatisticalAnalysis/scripts/data_os.csv\")\n",
    "log_norm_counts = pd.read_csv(r\"/home/rafaed/work/RO_src/Projects/THORA/StatisticalAnalysis/scripts/log_normalized_counts_df.csv\")\n",
    "adata_nmf = sc.read_h5ad(r\"/mnt/work/RO_src/Projects/THORA/DataProcessing/data/processed/adata_cp_full_preprocessed.h5ad\")\n",
    "\n",
    "km_data_ttp.rename(columns={\"tend\": \"tend_ttp\"}, inplace=True)\n",
    "km_data_os.rename(columns={\"tend\": \"tend_os\"}, inplace=True)\n",
    "km_data_ttp.drop(columns=['ERCC1', 'ERCC2',\n",
    "       'ERCC5', 'BRCA1', 'TUBB3', 'STK11', 'HIF1A','status', \"Unnamed: 0\",\"status\"], inplace=True)\n",
    "\n",
    "km_data_os.drop(columns=['ERCC1', 'ERCC2',\n",
    "       'ERCC5', 'BRCA1', 'TUBB3', 'STK11', 'HIF1A','status', \"Unnamed: 0\",\"status\"], inplace=True)\n",
    "common_cols = km_data_ttp.columns.intersection(km_data_os.columns)\n",
    "merged_df = pd.merge(km_data_ttp, km_data_os, on=list(common_cols))\n",
    "\n",
    "merged_data = pd.merge(merged_df, log_norm_counts, on=\"ID_Sample\")\n",
    "merged_df.set_index(\"ID_Sample\", inplace=True)\n",
    "merged_data.set_index(\"ID_Sample\", inplace=True)\n",
    "\n",
    "adata_nmf = revert_from_conversion(adata_nmf)\n",
    "adata_nmf_cp = adata_nmf.copy()\n",
    "adata_nmf_cp.obs.set_index(\"ID_Sample\", inplace=True)\n",
    "\n",
    "# Get the common indices\n",
    "common_idx = adata_nmf_cp.obs.index.isin(merged_data.index)\n",
    "\n",
    "# Subset adata_nmf to only keep samples that are in km_data_os\n",
    "adata_nmf_cp = adata_nmf_cp[common_idx].copy()\n",
    "\n",
    "# Now you can safely assign the new observation dataframe\n",
    "adata_nmf_cp.obs = merged_data\n",
    "adata_nmf_cp.obs.rename(columns={\"status_os\":\"status-os\"}, inplace=True)\n",
    "adata_nmf_cp.obs['status-os'] = adata_nmf_cp.obs['status-os'].map({0: 'Alive', 1: 'Dead'})\n",
    "adata_nmf_cp.obs.rename(columns={\"status_ttp\":\"status-ttp\"}, inplace=True)\n",
    "adata_nmf_cp.obs['status-ttp'] = adata_nmf_cp.obs['status-ttp'].map({0: 'Did not progress', 1: 'Progressed'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate gene sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gene_sets(merged_data, adata, top_genes, layer=\"lognormalized_counts\", endpoint=\"os\"):\n",
    "    \"\"\"\n",
    "    Evaluate different numbers of top genes for each comparison using Cox models.\n",
    "    Includes risk score calculation, KM curves, and time-dependent ROC analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    merged_data : pandas.DataFrame\n",
    "        DataFrame containing the survival data and gene expression data\n",
    "    top_genes : dict\n",
    "        Dictionary with comparisons as keys and lists of gene names as values\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing results_df, best_models, coefficient_dfs, and risk scores\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Store results\n",
    "    results = []\n",
    "    # Dictionary to store best models and their info\n",
    "    best_models = {}\n",
    "\n",
    "    expr = pd.DataFrame(adata.layers[layer], index=adata.obs.index, columns = adata.var.index).reset_index()\n",
    "    expr.set_index(\"ID_Sample\",inplace=True)\n",
    "\n",
    "    # Loop through each comparison in top_genes\n",
    "    for comparison in top_genes.keys():\n",
    "        print(f\"\\nProcessing comparison: {comparison}\")\n",
    "        comparison_best_score = -np.inf\n",
    "        comparison_best_info = None\n",
    "\n",
    "        # Loop through different numbers of genes\n",
    "        for n_genes in range(5, len(top_genes[comparison]), 5):\n",
    "            print(f\"Testing with top {n_genes} genes\")\n",
    "            \n",
    "            # Select features\n",
    "            selected_genes = top_genes[comparison][:n_genes]\n",
    "            try:\n",
    "                X =expr[selected_genes]\n",
    "                print(X)\n",
    "            except Exception as e:\n",
    "                print(f\"{e}\")\n",
    "                continue\n",
    "            # Store ID_Sample separately and set it as index for X_model\n",
    "            # sample_ids = merged_data.index\n",
    "            # X_model.index = sample_ids\n",
    "            \n",
    "            # Create the structured array for the full dataset\n",
    "            status_bool = merged_data[f'status-{endpoint}'].astype(bool)\n",
    "            time = merged_data[f'tend_{endpoint}']\n",
    "            y_structured = np.zeros(len(time), dtype=[('status', bool), ('time', float)])\n",
    "            y_structured['status'] = status_bool\n",
    "            y_structured['time'] = time\n",
    "            \n",
    "            # Split the data\n",
    "            X_train, X_test, y_train_idx, y_test_idx = train_test_split(\n",
    "                X, \n",
    "                np.arange(len(y_structured)), \n",
    "                test_size=0.2, \n",
    "                random_state=42, \n",
    "                stratify=status_bool\n",
    "            )\n",
    "            \n",
    "            # Create structured arrays for train and test sets\n",
    "            y_train = y_structured[y_train_idx]\n",
    "            y_test = y_structured[y_test_idx]\n",
    "            \n",
    "            # Fit initial model to get alphas\n",
    "            coxnet_pipe = make_pipeline(CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.01, max_iter=1000))\n",
    "            coxnet_pipe.fit(X_train, y_train)\n",
    "            estimated_alphas = coxnet_pipe.named_steps[\"coxnetsurvivalanalysis\"].alphas_\n",
    "            \n",
    "            # Perform cross-validation\n",
    "            cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "            gcv = GridSearchCV(\n",
    "                make_pipeline(CoxnetSurvivalAnalysis(l1_ratio=0.9)),\n",
    "                param_grid={\"coxnetsurvivalanalysis__alphas\": [[v] for v in estimated_alphas]},\n",
    "                cv=cv,\n",
    "                error_score=0.5,\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            ).fit(X_train, y_train)\n",
    "            alphas = [alpha[0] for alpha in gcv.cv_results_['param_coxnetsurvivalanalysis__alphas']]\n",
    "\n",
    "            # Accessing the mean and std test scores from grid search results\n",
    "            mean = gcv.cv_results_['mean_test_score']\n",
    "            std = gcv.cv_results_['std_test_score']\n",
    "\n",
    "            # Plotting the performance\n",
    "            fig, ax = plt.subplots(figsize=(9, 6))\n",
    "            ax.plot(alphas, mean, label='Mean Concordance Index')\n",
    "            ax.fill_between(alphas, mean - std, mean + std, alpha=0.15)\n",
    "            ax.set_xscale(\"log\")  # Log scale for the x-axis (alphas)\n",
    "            ax.set_ylabel(\"Concordance Index\")  # Y-axis label\n",
    "            ax.set_xlabel(\"Alpha\")  # X-axis label (alpha values)\n",
    "\n",
    "            # Plotting the best alpha from grid search\n",
    "            best_alpha = gcv.best_params_[\"coxnetsurvivalanalysis__alphas\"][0]\n",
    "            ax.axvline(best_alpha, c=\"C1\", label=\"Best Alpha\")  # Line at best alpha\n",
    "\n",
    "            # Adding a horizontal line at concordance index 0.5\n",
    "            ax.axhline(0.5, color=\"grey\", linestyle=\"--\", label=\"Random Concordance\")\n",
    "\n",
    "            # Add grid and legend\n",
    "            ax.grid(True)\n",
    "            ax.legend()\n",
    "\n",
    "            # Display the plot\n",
    "            plt.show()\n",
    "            # Get best model\n",
    "            best_model = gcv.best_estimator_.named_steps[\"coxnetsurvivalanalysis\"]\n",
    "            \n",
    "            # Make predictions\n",
    "            train_predictions = best_model.predict(X_train)\n",
    "            test_predictions = best_model.predict(X_test)\n",
    "            \n",
    "            # Calculate concordance indices\n",
    "            train_cindex = concordance_index_censored(\n",
    "                y_train['status'],\n",
    "                y_train['time'],\n",
    "                train_predictions\n",
    "            )[0]\n",
    "            \n",
    "            test_cindex = concordance_index_censored(\n",
    "                y_test['status'],\n",
    "                y_test['time'],\n",
    "                test_predictions\n",
    "            )[0]\n",
    "            \n",
    "            # Use predictions directly as risk scores\n",
    "            train_risk_scores = train_predictions\n",
    "            test_risk_scores = test_predictions\n",
    "            \n",
    "            # Find optimal cutoff using median in training set\n",
    "            risk_cutoff = np.median(train_risk_scores)\n",
    "            \n",
    "            # Assign risk groups\n",
    "            train_risk_groups = (train_risk_scores > risk_cutoff).astype(int)\n",
    "            test_risk_groups = (test_risk_scores > risk_cutoff).astype(int)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'comparison': comparison,\n",
    "                'n_genes': n_genes,\n",
    "                'train_cindex': train_cindex,\n",
    "                'test_cindex': test_cindex,\n",
    "                'best_alpha': gcv.best_params_[\"coxnetsurvivalanalysis__alphas\"][0],\n",
    "                'cv_score': gcv.best_score_,\n",
    "                'risk_cutoff': risk_cutoff,\n",
    "                'train_high_risk_n': sum(train_risk_groups),\n",
    "                'test_high_risk_n': sum(test_risk_groups)\n",
    "            })\n",
    "            \n",
    "            # Update best model info if this is the best test score so far for this comparison\n",
    "            if test_cindex > comparison_best_score:\n",
    "                comparison_best_score = test_cindex\n",
    "                comparison_best_info = {\n",
    "                    'model': best_model,\n",
    "                    'n_genes': n_genes,\n",
    "                    'test_cindex': test_cindex,\n",
    "                    'train_cindex': train_cindex,\n",
    "                    'X_train': X_train,\n",
    "                    'X_test': X_test,\n",
    "                    'y_train': y_train,\n",
    "                    'y_test': y_test,\n",
    "                    'selected_genes': selected_genes,\n",
    "                }\n",
    "            \n",
    "            print(f\"Train C-index: {train_cindex:.3f}\")\n",
    "            print(f\"Test C-index: {test_cindex:.3f}\")\n",
    "        \n",
    "        # Store best model info for this comparison\n",
    "        best_models[comparison] = comparison_best_info\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Create coefficient DataFrames for each best model\n",
    "    coef_dfs = {}\n",
    "    for comparison, model_info in best_models.items():\n",
    "        best_coefs = pd.DataFrame(\n",
    "            model_info['model'].coef_,\n",
    "            index=model_info['X_train'].columns,\n",
    "            columns=[\"coefficient\"]\n",
    "        )\n",
    "        coef_dfs[comparison] = best_coefs\n",
    "\n",
    "    # Plot results for best models\n",
    "    for comparison, model_info in best_models.items():\n",
    "        # Get the best model data\n",
    "        best_model = model_info['model']\n",
    "        X_train = model_info['X_train']\n",
    "        X_test = model_info['X_test']\n",
    "        y_train = model_info['y_train']\n",
    "        y_test = model_info['y_test']\n",
    "        n_genes = model_info['n_genes']\n",
    "        \n",
    "        # Recalculate predictions and use them directly as risk scores\n",
    "        train_predictions = best_model.predict(X_train)\n",
    "        test_predictions = best_model.predict(X_test)\n",
    "        \n",
    "        # Use predictions directly as risk scores\n",
    "        train_risk_scores = train_predictions\n",
    "        test_risk_scores = test_predictions\n",
    "        \n",
    "        # Find optimal cutoff using median in training set\n",
    "        risk_cutoff = np.median(train_risk_scores)\n",
    "        \n",
    "        # Assign risk groups\n",
    "        train_risk_groups = (train_risk_scores > risk_cutoff).astype(int)\n",
    "        test_risk_groups = (test_risk_scores > risk_cutoff).astype(int)\n",
    "        \n",
    "        # Plot KM curves for best model\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for group in [0, 1]:\n",
    "            mask = train_risk_groups == group\n",
    "            if np.any(mask):\n",
    "                time, survival_prob = kaplan_meier_estimator(\n",
    "                    y_train['status'][mask],\n",
    "                    y_train['time'][mask]\n",
    "                )\n",
    "                plt.step(time, survival_prob, \n",
    "                        label=f\"{'High' if group else 'Low'} Risk (train)\")\n",
    "        \n",
    "        for group in [0, 1]:\n",
    "            mask = test_risk_groups == group\n",
    "            if np.any(mask):\n",
    "                time, survival_prob = kaplan_meier_estimator(\n",
    "                    y_test['status'][mask],\n",
    "                    y_test['time'][mask]\n",
    "                )\n",
    "                plt.step(time, survival_prob, '--',\n",
    "                        label=f\"{'High' if group else 'Low'} Risk (test)\")\n",
    "        \n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Survival Probability')\n",
    "        plt.title(f'Kaplan-Meier Curves by Risk Group\\nBest Model for {comparison} ({n_genes} genes)')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate time-dependent ROC curve\n",
    "        times = np.array([365, 730, 1095])  # 1, 2, and 3 years\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        auc, mean_auc = cumulative_dynamic_auc(\n",
    "            y_train, y_test,\n",
    "            test_predictions,\n",
    "            times\n",
    "        )\n",
    "        \n",
    "        for i, t in enumerate(times):\n",
    "            if i == 0:\n",
    "                ax.plot(times, auc, marker=\"o\", color=\"crimson\", label=\"AUC\")\n",
    "            else:\n",
    "                ax.plot(times, auc, marker=\"o\", color=\"crimson\")\n",
    "            ax.text(\n",
    "                times[i], auc[i] + 0.02,\n",
    "                f\"{t/365:.0f} year AUC={auc[i]:.3f}\",\n",
    "                ha=\"center\",\n",
    "            )\n",
    "        \n",
    "        ax.plot([times[0], times[-1]], [0.5, 0.5], color=\"gray\", linestyle=\"--\")\n",
    "        ax.set_xlabel(\"Days\")\n",
    "        ax.set_ylabel(\"Time-dependent AUC\")\n",
    "        ax.set_title(f\"Time-dependent ROC\\nBest Model for {comparison} ({n_genes} genes)\")\n",
    "        ax.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Print best results and plot coefficients for each comparison\n",
    "    fig, axes = plt.subplots(len(best_models), 1, figsize=(10, 6*len(best_models)))\n",
    "    if len(best_models) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for idx, (comparison, model_info) in enumerate(best_models.items()):\n",
    "        print(f\"\\n=== Best Model for {comparison} ===\")\n",
    "        print(f\"Number of genes: {model_info['n_genes']}\")\n",
    "        print(f\"Test C-index: {model_info['test_cindex']:.3f}\")\n",
    "        print(f\"Train C-index: {model_info['train_cindex']:.3f}\")\n",
    "        \n",
    "        # Get non-zero coefficients\n",
    "        best_coefs = coef_dfs[comparison]\n",
    "        non_zero_coefs = best_coefs.query(\"coefficient != 0\")\n",
    "        coef_order = non_zero_coefs.abs().sort_values(\"coefficient\").index\n",
    "        \n",
    "        print(f\"Number of non-zero coefficients: {len(non_zero_coefs)}\")\n",
    "        \n",
    "        # Plot coefficients\n",
    "        non_zero_coefs.loc[coef_order].plot.barh(ax=axes[idx], legend=False)\n",
    "        axes[idx].set_xlabel(\"coefficient\")\n",
    "        axes[idx].set_title(f\"Coefficients for {comparison}\")\n",
    "        axes[idx].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Create performance plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    for comparison in top_genes.keys():\n",
    "        comparison_results = results_df[results_df['comparison'] == comparison]\n",
    "        ax.plot(comparison_results['n_genes'], comparison_results['test_cindex'], \n",
    "                marker='o', label=f'{comparison} (test)')\n",
    "        ax.plot(comparison_results['n_genes'], comparison_results['train_cindex'], \n",
    "                marker='o', linestyle='--', label=f'{comparison} (train)')\n",
    "\n",
    "    ax.set_xlabel('Number of genes')\n",
    "    ax.set_ylabel('Concordance Index')\n",
    "    ax.set_title('Performance vs Number of Genes')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'results_df': results_df,\n",
    "        'best_models': best_models,\n",
    "        'coefficient_dfs': coef_dfs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get risk scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sksurv.compare import compare_survival\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "def plot_risk_profile(risk_scores_df, merged_data, gene_coefficients, optimal_cutpoint):\n",
    "    \"\"\"\n",
    "    Create a combined plot showing risk scores, survival status, and gene expression profiles.\n",
    "    \"\"\"\n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 12), \n",
    "                            gridspec_kw={'height_ratios': [1, 1, 2]},\n",
    "                            sharex=True)\n",
    "    plt.subplots_adjust(hspace=0.05)\n",
    "\n",
    "    # 1. Risk score distribution\n",
    "    axes[0].scatter(range(len(risk_scores_df)), \n",
    "                   risk_scores_df['risk_score'],\n",
    "                   c=['red' if x == 'high' else 'blue' for x in risk_scores_df['risk_group']], \n",
    "                   s=30)\n",
    "    axes[0].axvline(x=sum(risk_scores_df['risk_group'] == 'low'), \n",
    "                    color='red', linestyle='--')\n",
    "    axes[0].set_ylabel('Risk score')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # 2. Survival status\n",
    "    survival_data = pd.DataFrame({\n",
    "        'time': risk_scores_df['time'],\n",
    "        'status': risk_scores_df['status'],\n",
    "    })\n",
    "    \n",
    "    scatter = axes[1].scatter(range(len(survival_data)), \n",
    "                            survival_data['time'],\n",
    "                            c=['red' if s else 'blue' for s in survival_data['status']],\n",
    "                            s=30)\n",
    "    axes[1].set_ylabel('Time (days)')\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Add legend for survival status\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w', \n",
    "                            markerfacecolor='red', label='Death', markersize=8),\n",
    "                      Line2D([0], [0], marker='o', color='w', \n",
    "                            markerfacecolor='blue', label='Live', markersize=8)]\n",
    "    axes[1].legend(handles=legend_elements, loc='right')\n",
    "\n",
    "    # 3. Gene expression heatmap\n",
    "    genes = list(gene_coefficients.keys())\n",
    "    expression_data = merged_data[genes].iloc[risk_scores_df.index]\n",
    "    \n",
    "    # Z-scale the expression data\n",
    "    expression_data_scaled = pd.DataFrame(\n",
    "        stats.zscore(expression_data, axis=0),\n",
    "        columns=expression_data.columns,\n",
    "        index=expression_data.index\n",
    "    )\n",
    "    \n",
    "    # Create heatmap with z-scaled data\n",
    "    sns.heatmap(expression_data_scaled.T, \n",
    "                cmap='RdBu_r',\n",
    "                center=0,\n",
    "                ax=axes[2],\n",
    "                cbar_kws={'label': 'Z-score'})\n",
    "    \n",
    "    axes[2].set_xlabel('Patients (ranked by risk score)')\n",
    "    axes[2].set_ylabel('Genes')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def calculate_risk_scores(merged_data, coef_df):\n",
    "    \"\"\"\n",
    "    Calculate risk scores and find optimal cutpoint for stratification using sksurv.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Define the coefficients\n",
    "    original_coefficients = {coef_df.index[i]: round(coef_df.iloc[i, 0],4) for i in range(len(coef_df))}\n",
    "    \n",
    "    # Alternative names for PDCD1\n",
    "    pdcd1_alternatives = ['PDCD1', 'PD1', 'CD279', 'PD-1']\n",
    "    \n",
    "    # Check which genes are available and create final coefficients dict\n",
    "    coefficients = {}\n",
    "    for gene, coef in original_coefficients.items():\n",
    "        if gene in merged_data.columns:\n",
    "            coefficients[gene] = coef\n",
    "    \n",
    "    print(\"\\nGenes used in risk score calculation:\")\n",
    "    for gene, coef in coefficients.items():\n",
    "        print(f\"{gene}: {coef}\")\n",
    "    \n",
    "    print(\"\\nGenes not found in data and skipped:\")\n",
    "    missing_genes = set(original_coefficients.keys()) - set(coefficients.keys())\n",
    "    for gene in missing_genes:\n",
    "        print(gene)\n",
    "    \n",
    "    # Calculate risk scores\n",
    "    risk_scores = []\n",
    "    for idx, row in merged_data.iterrows():\n",
    "        # Calculate the risk score\n",
    "        risk_score = sum(coefficients[gene] * row[gene] for gene in coefficients.keys())\n",
    "        risk_scores.append({\n",
    "            'ID_Sample': row['ID_Sample'],\n",
    "            'risk_score': risk_score,\n",
    "            'time': row['tend'],\n",
    "            'status': row['status_os']\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    risk_scores_df = pd.DataFrame(risk_scores)\n",
    "    \n",
    "    # Create survival data structure\n",
    "    survival_data = np.zeros(len(merged_data), dtype=[('status', bool), ('time', float)])\n",
    "    survival_data['status'] = merged_data['status_os'].astype(bool)\n",
    "    survival_data['time'] = merged_data['tend']\n",
    "    \n",
    "    # Find optimal cutpoint using log-rank statistics\n",
    "    max_statistic = -np.inf\n",
    "    optimal_cutpoint = None\n",
    "    \n",
    "    # Test cutpoints between 15th and 85th percentiles\n",
    "    percentiles = np.arange(15, 86, 1)\n",
    "    cutpoints = np.percentile(risk_scores_df['risk_score'], percentiles)\n",
    "    \n",
    "    for cutpoint in cutpoints:\n",
    "        groups = (risk_scores_df['risk_score'] > cutpoint).astype(int)\n",
    "        chisq, pvalue = compare_survival(survival_data, groups)\n",
    "\n",
    "        print(f\"The p-value for {cutpoint} is {pvalue} with a chi-stat of {chisq} using the following groups \")\n",
    "\n",
    "        if chisq > max_statistic:\n",
    "            max_statistic = chisq\n",
    "            optimal_cutpoint = cutpoint\n",
    "            optimal_pvalue = pvalue\n",
    "    \n",
    "    # Assign risk groups - higher scores = higher risk\n",
    "    risk_scores_df['risk_group'] = (risk_scores_df['risk_score'] > optimal_cutpoint).map({True: 'high', False: 'low'})\n",
    "    \n",
    "    # Sort by risk score for visualization\n",
    "    risk_scores_df = risk_scores_df.sort_values('risk_score')\n",
    "    risk_scores_df['rank'] = range(len(risk_scores_df))\n",
    "    \n",
    "    # Create the combined risk profile plot\n",
    "    plot_risk_profile(risk_scores_df, merged_data, coefficients, optimal_cutpoint)\n",
    "    \n",
    "    # Calculate HR using Cox model\n",
    "    X = (risk_scores_df['risk_group'] == 'high').values.reshape(-1, 1)\n",
    "    y = np.zeros(len(X), dtype=[('status', bool), ('time', float)])\n",
    "    y['status'] = risk_scores_df['status'].astype(bool)\n",
    "    y['time'] = risk_scores_df['time']\n",
    "    \n",
    "    cph = CoxPHSurvivalAnalysis()\n",
    "    cph.fit(X, y)\n",
    "    hr = np.exp(cph.coef_[0])\n",
    "    \n",
    "    # Plot Kaplan-Meier curves with statistics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for group, color in zip(['high', 'low'], ['red', 'blue']):\n",
    "        mask = risk_scores_df['risk_group'] == group\n",
    "        if sum(mask) > 0:\n",
    "            time = risk_scores_df.loc[mask, 'time']\n",
    "            status = risk_scores_df.loc[mask, 'status'].astype(bool)\n",
    "            \n",
    "            time_km, survival_prob = kaplan_meier_estimator(\n",
    "                status,\n",
    "                time\n",
    "            )\n",
    "            \n",
    "            plt.step(time_km, survival_prob, where=\"post\", \n",
    "                    label=f\"{group.capitalize()} risk (n={sum(mask)})\",\n",
    "                    color=color)\n",
    "    \n",
    "    # Add HR and p-value to the plot\n",
    "    stats_text = (f'HR = {hr:.2f}\\n'\n",
    "                 f'Log-rank P = {optimal_pvalue:.2e}')\n",
    "    plt.text(0.05, 0.15, stats_text, transform=plt.gca().transAxes,\n",
    "             bbox=dict(facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Survival probability')\n",
    "    plt.title('Kaplan-Meier Curves by Risk Group')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()  \n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nRisk group sizes:\")\n",
    "    print(risk_scores_df['risk_group'].value_counts())\n",
    "    print(f\"\\nOptimal cutpoint: {optimal_cutpoint:.4f}\")\n",
    "    print(f\"Log-rank test p-value: {optimal_pvalue:.2e}\")\n",
    "    print(f\"Hazard Ratio: {hr:.2f}\")\n",
    "    \n",
    "    return risk_scores_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "source_paths = {\n",
    "    #\"I-NE vs Rest\": \"/home/rafaed/work/RO_src/STAnalysis/notebooks/downstream/Bulk RNA/deg_analysis_results_de_novo/deg_results_4_vs_rest.csv\",\n",
    "    #\"I-nNE vs Rest\": \"/home/rafaed/work/RO_src/STAnalysis/notebooks/downstream/Bulk RNA/deg_analysis_results_de_novo/deg_results_3_vs_rest.csv\",\n",
    "    #\"N vs Rest\": \"/home/rafaed/work/RO_src/STAnalysis/notebooks/downstream/Bulk RNA/deg_analysis_results_de_novo/deg_results_2_vs_rest.csv\",\n",
    "    #\"A vs Rest\": \"/home/rafaed/work/RO_src/STAnalysis/notebooks/downstream/Bulk RNA/deg_analysis_results_de_novo/deg_results_1_vs_rest.csv\",\n",
    "    \"Alive vs Dead\": \"/home/rafaed/work/RO_src/STAnalysis/notebooks/downstream/Bulk RNA/deg_analysis_os/DEG_results_Alive_vs_Dead.csv\"\n",
    "}\n",
    "\n",
    "# Create CSV file for status OS (dead vs alive)\n",
    "deg_os = DEGAnalysis(adata_nmf_cp, design_factor='status-os', layer='raw_counts', output_dir=\"./deg_analysis_os\")\n",
    "deg_os.create_dds()\n",
    "deg_os.run_comparisons()\n",
    "deg_os.save_results()\n",
    "deg_os.create_volcano_grid()\n",
    "results_deg_os = deg_os.get_results()\n",
    "os_top_genes = get_top_genes(source_paths = {\"Alive vs Dead\": \"/home/rafaed/work/RO_src/STAnalysis/notebooks/downstream/Bulk RNA/deg_analysis_os/DEG_results_Alive_vs_Dead.csv\"}, n_genes = 100)\n",
    "\n",
    "# Create CSV file for status TTP (progressed vs didn't progress)\n",
    "deg_ttp = DEGAnalysis(adata_nmf_cp, design_factor='status-ttp', layer='raw_counts', output_dir=\"./deg_analysis_ttp\")\n",
    "deg_ttp.create_dds()\n",
    "deg_ttp.run_comparisons()\n",
    "deg_ttp.save_results()\n",
    "deg_ttp.create_volcano_grid()\n",
    "results_deg_ttp = deg_ttp.get_results()\n",
    "ttp_top_genes = get_top_genes(source_paths = {\"Did not progress vs Progressed\": \"/home/rafaed/work/RO_src/STAnalysis/notebooks/downstream/Bulk RNA/deg_analysis_ttp/DEG_results_Did not progress_vs_Progressed.csv\"}, n_genes = 100)\n",
    "\n",
    "# Retrieve the coefficients from LASSO Cox from the DEG genes\n",
    "results_ttp = evaluate_gene_sets(merged_data, adata_nmf_cp, ttp_top_genes, endpoint=\"ttp\")\n",
    "results_df_ttp = results_ttp['results_df']\n",
    "best_models_ttp = results_ttp['best_models']\n",
    "coefficient_dfs_ttp = results_ttp['coefficient_dfs']\n",
    "\n",
    "results_os = evaluate_gene_sets(merged_data, adata_nmf_cp, os_top_genes, endpoint=\"os\")\n",
    "results_df_os = results_os['results_df']\n",
    "best_models_os = results_os['best_models']\n",
    "coefficient_dfs_os = results_os['coefficient_dfs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the risk scores\n",
    "risk_scores_df_ttp = calculate_risk_scores(adata_nmf_cp, coef_df = coefficient_dfs_ttp[\"Did not progress vs Progressed\"])\n",
    "risk_scores_df_os = calculate_risk_scores(adata_nmf_cp, coef_df = coefficient_dfs_os[\"Alive vs Dead\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bulk_rna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
